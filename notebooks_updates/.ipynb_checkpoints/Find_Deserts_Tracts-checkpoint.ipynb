{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "black-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from functools import cache\n",
    "from scipy.spatial import KDTree\n",
    "from haversine import haversine\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced:\n",
    "# https://towardsdatascience.com/finding-time-dependent-travel-times-between-every-pair-of-locations-in-manhattan-c3c48b0db7ba\n",
    "# https://towardsdatascience.com/shortest-path-algorithm-with-osm-walking-network-6d2863ae96be\n",
    "# https://osmnx.readthedocs.io/en/stable/osmnx.html and https://github.com/gboeing/osmnx\n",
    "# https://movement.uber.com/?lang=en-US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "derived-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### SET CITY VARS HERE ###########################################################\n",
    "\n",
    "place = 'Cincinnati, Ohio'\n",
    "#place = 'Atlanta, Georgia'\n",
    "#place = 'Seattle, Washington'\n",
    "#place = 'Houston, Texas'\n",
    "#place = 'San Francisco, California'\n",
    "#place = 'New York, New York'\n",
    "\n",
    "place_abbr = 'cinci'\n",
    "#place_abbr = 'seattle'\n",
    "#place_abbr = 'nyc'\n",
    "#place_abbr = 'houston'\n",
    "#place_abbr = 'sf'\n",
    "#place_abbr = 'atlanta'\n",
    "\n",
    "savename = 'data/tract_desert_measures/' + place_abbr + '_desert_tracts.csv'\n",
    "speed_path = 'data/2020_speeds_cincinnati.csv' #download data yourself\n",
    "tracts_path = 'data/tract_centers/tractcenters_cinci.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d14e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tractcenters = pd.read_csv(tracts_path)\n",
    "lats = tractcenters['INTPTLAT'].to_numpy(copy=True)\n",
    "lons = tractcenters['INTPTLONG'].to_numpy(copy=True)\n",
    "tracts = tractcenters['GEOID'].to_numpy(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "black-fifteen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got graph\n",
      "Got speeds\n",
      "Got travel times\n",
      "Got largest connected component\n"
     ]
    }
   ],
   "source": [
    "# Get the graph and the speeds associated with all edges\n",
    "graph = ox.graph_from_place(place, network_type='drive')\n",
    "print('Got graph')\n",
    "graph = ox.add_edge_speeds(graph)\n",
    "print('Got speeds')\n",
    "graph = ox.add_edge_travel_times(graph)\n",
    "print('Got travel times')\n",
    "graph = ox.utils_graph.get_largest_component(graph, strongly=True)\n",
    "print('Got largest connected component')\n",
    "#ox.save_graphml(graph, r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\new_york_metro_area_cleaned.graphml')\n",
    "#graph = ox.load_graphml(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\new_york_metro_area_cleaned.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caroline-purse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))\n"
     ]
    }
   ],
   "source": [
    "# Find all food stores\n",
    "food_tags = {'shop': 'supermarket', 'amenity': 'marketplace'}\n",
    "food_places = ox.geometries_from_place(place, food_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "recorded-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Polygons with a single point\n",
    "food_places.loc[food_places['geometry'].type == 'Polygon', 'geometry'] = food_places.loc[food_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "synthetic-retailer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))\n",
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geometries.py:805: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  for merged_outer_linestring in list(merged_outer_linestrings):\n",
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geometries.py:805: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for merged_outer_linestring in list(merged_outer_linestrings):\n"
     ]
    }
   ],
   "source": [
    "# Find all major green places or recreational areas\n",
    "physical_tags = {'leisure': ['park', 'recreation_ground', 'playground', 'fitness_station', 'sports_centre', 'nature_reserve', 'pitch']}\n",
    "physical_places = ox.geometries_from_place(place, physical_tags)\n",
    "physical_places.loc[physical_places['geometry'].type == 'Polygon', 'geometry'] = physical_places.loc[physical_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facial-relevance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))\n"
     ]
    }
   ],
   "source": [
    "# Find public transit\n",
    "transport_tags = {'public_transport': ['platform', 'stop_position'], 'highway': ['bus_stop', 'platform'],\n",
    "                 'railway': ['subway_entrance', 'station', 'tram', 'tram_stop'], 'station': 'subway'}\n",
    "transport_places = ox.geometries_from_place(place, transport_tags)\n",
    "transport_places.loc[transport_places['geometry'].type == 'Polygon', 'geometry'] = transport_places.loc[transport_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecological-hotel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))\n",
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geometries.py:805: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  for merged_outer_linestring in list(merged_outer_linestrings):\n",
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geometries.py:805: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for merged_outer_linestring in list(merged_outer_linestrings):\n"
     ]
    }
   ],
   "source": [
    "# Find libraries and schools\n",
    "education_tags = {'amenity': ['library', 'school', 'kindergarten']}\n",
    "education_places = ox.geometries_from_place(place, education_tags)\n",
    "education_places.loc[education_places['geometry'].type == 'Polygon', 'geometry'] = education_places.loc[education_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "institutional-senegal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geocoder.py:110: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  gdf = gdf.append(_geocode_query_to_gdf(q, wr, by_osmid))\n",
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geometries.py:805: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  for merged_outer_linestring in list(merged_outer_linestrings):\n",
      "/opt/anaconda3/envs/ox/lib/python3.10/site-packages/osmnx/geometries.py:805: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for merged_outer_linestring in list(merged_outer_linestrings):\n"
     ]
    }
   ],
   "source": [
    "# Find places of worship\n",
    "worship_tags = {'amenity': 'place_of_worship'}\n",
    "worship_places = ox.geometries_from_place(place, worship_tags)\n",
    "worship_places.loc[worship_places['geometry'].type == 'Polygon', 'geometry'] = worship_places.loc[worship_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dress-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify everything\n",
    "food_places = food_places['geometry'].droplevel(0)\n",
    "physical_places = physical_places['geometry'].droplevel(0)\n",
    "transport_places = transport_places['geometry'].droplevel(0)\n",
    "education_places = education_places['geometry'].droplevel(0)\n",
    "worship_places = worship_places['geometry'].droplevel(0)\n",
    "food_places = food_places[food_places.type == 'Point']\n",
    "physical_places = physical_places[physical_places.type == 'Point']\n",
    "transport_places = transport_places[transport_places.type == 'Point']\n",
    "education_places = education_places[education_places.type == 'Point']\n",
    "worship_places = worship_places[worship_places.type == 'Point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acquired-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_raw = pd.read_csv(speed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "medical-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "speed_raw.drop(columns=['quarter', 'year', 'segment_id', 'start_junction_id', 'end_junction_id'], inplace=True)\n",
    "# Noon seems like a fair time\n",
    "speed_raw = speed_raw[speed_raw['hour_of_day'] == 12]\n",
    "speed_raw.set_index('osm_way_id', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tracked-steering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 20155/20155 [00:02<00:00, 8169.27it/s]\n"
     ]
    }
   ],
   "source": [
    "real_calculation = 0\n",
    "for edge in tqdm(graph.edges):\n",
    "   # length is meters, speed_kph is kph (duh), maxspeed has units in string, and travel_time is seconds\n",
    "    e = graph[edge[0]][edge[1]][edge[2]]\n",
    "    if isinstance(e['osmid'], list):\n",
    "       # Some graph edges are made up of multiple OSM ways apparently\n",
    "       for osmid in e['osmid']:\n",
    "            try:\n",
    "                meters_per_second = speed_raw.at[osmid, 'speed_mph_mean']*0.44704    # Convert to meters/sec\n",
    "                time = e['length']/meters_per_second\n",
    "                real_calculation += 1\n",
    "                break\n",
    "            except (KeyError, ZeroDivisionError):\n",
    "                time = e['travel_time']     # Backup (i.e. length/speed limit) if Uber data isn't available\n",
    "    else:\n",
    "        try:\n",
    "            meters_per_second = speed_raw.at[e['osmid'], 'speed_mph_mean']*0.44704\n",
    "            time = e['length']/meters_per_second\n",
    "            real_calculation += 1\n",
    "        except (KeyError, ZeroDivisionError):\n",
    "            time = e['travel_time']\n",
    "    if isinstance(time, pd.Series):\n",
    "       # TODO Bug check why this is happening, but not late at night\n",
    "        time = time.mean()\n",
    "    graph[edge[0]][edge[1]][edge[2]]['actual_travel_time'] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "quarterly-child",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 108\n"
     ]
    }
   ],
   "source": [
    "all_nearest_nodes, dists = ox.distance.nearest_nodes(graph, lons, lats, return_dist=True)\n",
    "# If it's more than 1km away from anything in the graph, then we probably don't want it\n",
    "all_nearest_nodes = np.asarray(all_nearest_nodes)#[np.asarray(dists) < 1700]\n",
    "#health = health[np.asarray(dists) < 1700]\n",
    "print('Number:', all_nearest_nodes.shape[0])\n",
    "food_closest_travel_times = np.full(all_nearest_nodes.shape[0], np.nan, dtype=np.float32)\n",
    "physical_closest_dist = food_closest_travel_times.copy()\n",
    "transport_closest_dist = food_closest_travel_times.copy()\n",
    "education_closest_travel_times = food_closest_travel_times.copy()\n",
    "worship_closest_travel_times = food_closest_travel_times.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continuing-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found food Number within 1km: 19 Number total: 19\n",
      "Found physical Number within 1km: 1175 Number total: 1175\n",
      "Found transport Number within 1km: 1885 Number total: 1885\n",
      "Found education Number within 1km: 180 Number total: 180\n",
      "Found worship Number within 1km: 258 Number total: 258\n"
     ]
    }
   ],
   "source": [
    "food_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in food_places], [x.y for x in food_places], return_dist=True)\n",
    "print('Found food', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 17000000), 'Number total:', len(food_nodes))\n",
    "food_nodes = np.asarray(food_nodes)[np.asarray(dists) < 17000000]\n",
    "physical_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in physical_places], [x.y for x in physical_places], return_dist=True)\n",
    "print('Found physical', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 1700000), 'Number total:', len(physical_nodes))\n",
    "physical_nodes = np.asarray(physical_nodes)[np.asarray(dists) < 1700000]\n",
    "transport_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in transport_places], [x.y for x in transport_places], return_dist=True)\n",
    "print('Found transport', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 17000000), 'Number total:', len(transport_nodes))\n",
    "transport_nodes = np.asarray(transport_nodes)[np.asarray(dists) < 1700000]\n",
    "education_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in education_places], [x.y for x in education_places], return_dist=True)\n",
    "print('Found education', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 1700000), 'Number total:', len(education_nodes))\n",
    "education_nodes = np.asarray(education_nodes)[np.asarray(dists) < 1700000]\n",
    "worship_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in worship_places], [x.y for x in worship_places], return_dist=True)\n",
    "print('Found worship', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 1700000), 'Number total:', len(worship_nodes))\n",
    "worship_nodes = np.asarray(worship_nodes)[np.asarray(dists) < 17000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abandoned-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_lat_lons = np.array([[graph.nodes[x]['x'] for x in food_nodes], [graph.nodes[x]['y'] for x in food_nodes]], dtype=np.float32).T\n",
    "physical_lat_lons = np.array([[graph.nodes[x]['x'] for x in physical_nodes], [graph.nodes[x]['y'] for x in physical_nodes]], dtype=np.float32).T\n",
    "transport_lat_lons = np.array([[graph.nodes[x]['x'] for x in transport_nodes], [graph.nodes[x]['y'] for x in transport_nodes]], dtype=np.float32).T\n",
    "education_lat_lons = np.array([[graph.nodes[x]['x'] for x in education_nodes], [graph.nodes[x]['y'] for x in education_nodes]], dtype=np.float32).T\n",
    "worship_lat_lons = np.array([[graph.nodes[x]['x'] for x in worship_nodes], [graph.nodes[x]['y'] for x in worship_nodes]], dtype=np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "attempted-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_tree = KDTree(food_lat_lons)\n",
    "physical_tree = KDTree(physical_lat_lons)\n",
    "transport_tree = KDTree(transport_lat_lons)\n",
    "education_tree = KDTree(education_lat_lons)\n",
    "worship_tree = KDTree(worship_lat_lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continent-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_wrapper(lat1, lon1, lat2, lon2):\n",
    "    return haversine((lat1, lon1), (lat2, lon2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "capital-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 108/108 [00:00<00:00, 7748.10it/s]\n"
     ]
    }
   ],
   "source": [
    "closest_food_nodes = []\n",
    "closest_education_nodes = []\n",
    "closest_worship_nodes = []\n",
    "for i, sample_node in tqdm(enumerate(all_nearest_nodes), total=len(all_nearest_nodes)):\n",
    "    idxes = food_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_food_nodes.append(food_nodes[idxes])\n",
    "    idx = physical_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=1)[1]\n",
    "    dist = haversine_wrapper(graph.nodes[sample_node]['y'], graph.nodes[sample_node]['x'], physical_lat_lons[idx, 1], physical_lat_lons[idx, 0])\n",
    "    physical_closest_dist[i] = dist\n",
    "    idx = transport_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=1)[1]\n",
    "    dist = haversine_wrapper(graph.nodes[sample_node]['y'], graph.nodes[sample_node]['x'], transport_lat_lons[idx, 1], transport_lat_lons[idx, 0])\n",
    "    transport_closest_dist[i] = dist\n",
    "    idxes = education_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_education_nodes.append(education_nodes[idxes])\n",
    "    idxes = worship_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_worship_nodes.append(worship_nodes[idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "weighted-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache    # Trying to speed things up a little\n",
    "def shortest_path(source, target):\n",
    "    return nx.shortest_path_length(graph, source=source, target=target, weight='actual_travel_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "black-decline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 108/108 [00:02<00:00, 36.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, sample_node in enumerate(tqdm(all_nearest_nodes)):\n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for food_node in closest_food_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, food_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = food_node\n",
    "    food_closest_travel_times[i] = current_shortest\n",
    "    \n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for education_node in closest_education_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, education_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = education_node\n",
    "    education_closest_travel_times[i] = current_shortest\n",
    "    \n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for worship_node in closest_worship_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, worship_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = worship_node\n",
    "    worship_closest_travel_times[i] = current_shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "willing-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "deserts_wtracts = np.vstack((food_closest_travel_times, physical_closest_dist, transport_closest_dist, education_closest_travel_times,\n",
    "                worship_closest_travel_times)).T\n",
    "columns = ['food_closest_travel_times', 'physical_closest_dist','transport_closest_dist', \n",
    "           'education_closest_travel_times', 'worship_closest_travel_times']\n",
    "desert_measures = pd.DataFrame(deserts_wtracts, columns=columns)\n",
    "if place == 'San Francisco, California':\n",
    "    tracts = tracts.tolist()\n",
    "    tracts = ['0'+str(x) for x in tracts]\n",
    "    desert_measures['GEOID'] = tracts\n",
    "else:\n",
    "    tracts = tracts.tolist()\n",
    "    tracts = [str(x) for x in tracts]\n",
    "    desert_measures['GEOID'] = tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8806db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "desert_measures.to_csv(savename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaea763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ox]",
   "language": "python",
   "name": "conda-env-ox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
