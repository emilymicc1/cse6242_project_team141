{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "black-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from functools import cache\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "derived-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced:\n",
    "# https://towardsdatascience.com/finding-time-dependent-travel-times-between-every-pair-of-locations-in-manhattan-c3c48b0db7ba\n",
    "# https://towardsdatascience.com/shortest-path-algorithm-with-osm-walking-network-6d2863ae96be\n",
    "# https://osmnx.readthedocs.io/en/stable/osmnx.html and https://github.com/gboeing/osmnx\n",
    "# https://movement.uber.com/?lang=en-US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considerable-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding box covering the greater NYC region\n",
    "bbox = (41.015, 40.497, -73.452, -74.745)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "black-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the graph and the speeds associated with all edges\n",
    "#graph = ox.graph_from_bbox(*bbox, network_type='drive')  # Could also use ox.graph_from_place('New York, New York')\n",
    "#graph = ox.add_edge_speeds(graph)\n",
    "#graph = ox.add_edge_travel_times(graph)\n",
    "#ox.save_graphml(graph, r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\new_york_metro_area.graphml')\n",
    "#graph = ox.utils_graph.get_largest_component(graph, strongly=True)\n",
    "#ox.save_graphml(graph, r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\new_york_metro_area_cleaned.graphml')\n",
    "graph = ox.load_graphml(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\new_york_metro_area_cleaned.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caroline-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all food stores\n",
    "food_tags = {'shop': 'supermarket', 'amenity': 'marketplace'}\n",
    "food_places = ox.geometries_from_bbox(*bbox, food_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "recorded-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Polygons with a single point\n",
    "food_places.loc[food_places['geometry'].type == 'Polygon', 'geometry'] = food_places.loc[food_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "synthetic-retailer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willd\\Anaconda3\\envs\\ox\\lib\\site-packages\\osmnx\\geometries.py:805: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  for merged_outer_linestring in list(merged_outer_linestrings):\n",
      "C:\\Users\\willd\\Anaconda3\\envs\\ox\\lib\\site-packages\\osmnx\\geometries.py:805: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for merged_outer_linestring in list(merged_outer_linestrings):\n"
     ]
    }
   ],
   "source": [
    "# Find all major green places or recreational areas\n",
    "physical_tags = {'leisure': 'park', 'leisure': 'recreation_ground', 'leisure': 'playground', 'leisure': 'fitness_station',\n",
    "                'leisure': 'sports_centre', 'leisure': 'nature_reserve', 'leisure': 'pitch'}\n",
    "physical_places = ox.geometries_from_bbox(*bbox, physical_tags)\n",
    "physical_places.loc[physical_places['geometry'].type == 'Polygon', 'geometry'] = physical_places.loc[physical_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facial-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find public transit\n",
    "transport_tags = {'public_transport': 'platform', 'public_transport': 'stop_position', 'highway': 'bus_stop', 'highway': 'platform',\n",
    "                 'railway': 'subway_entrance', 'railway': 'station', 'railway': 'tram', 'railway': 'tram_stop', 'station': 'subway'}\n",
    "transport_places = ox.geometries_from_bbox(*bbox, transport_tags)\n",
    "transport_places.loc[transport_places['geometry'].type == 'Polygon', 'geometry'] = transport_places.loc[transport_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecological-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find libraries and schools\n",
    "education_tags = {'amenity': 'library', 'amenity': 'school', 'amenity': 'kindergarten'}\n",
    "education_places = ox.geometries_from_bbox(*bbox, transport_tags)\n",
    "education_places.loc[education_places['geometry'].type == 'Polygon', 'geometry'] = education_places.loc[education_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "institutional-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find places of worship\n",
    "worship_tags = {'amenity': 'place_of_worship'}\n",
    "worship_places = ox.geometries_from_bbox(*bbox, transport_tags)\n",
    "worship_places.loc[worship_places['geometry'].type == 'Polygon', 'geometry'] = worship_places.loc[worship_places['geometry'].type == 'Polygon', 'geometry'].representative_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dress-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify everything\n",
    "food_places = food_places['geometry'].droplevel(0)\n",
    "physical_places = physical_places['geometry'].droplevel(0)\n",
    "transport_places = transport_places['geometry'].droplevel(0)\n",
    "education_places = education_places['geometry'].droplevel(0)\n",
    "worship_places = worship_places['geometry'].droplevel(0)\n",
    "food_places = food_places[food_places.type == 'Point']\n",
    "physical_places = physical_places[physical_places.type == 'Point']\n",
    "transport_places = transport_places[transport_places.type == 'Point']\n",
    "education_places = education_places[education_places.type == 'Point']\n",
    "worship_places = worship_places[worship_places.type == 'Point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acquired-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed_raw = pd.read_csv(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\2020_speeds_new_york.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "medical-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "#speed_raw.drop(columns=['quarter', 'year', 'segment_id', 'start_junction_id', 'end_junction_id'], inplace=True)\n",
    "# Assume people shop around 6pm after work?\n",
    "#speed_raw = speed_raw[speed_raw['hour_of_day'] == 18]\n",
    "#speed_raw.set_index('osm_way_id', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tracked-steering",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 1904630/1904630 [01:14<00:00, 25621.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for edge in tqdm(graph.edges):\n",
    "    # For some reason the travel times get loaded in as strings\n",
    "    e = graph[edge[0]][edge[1]][edge[2]]\n",
    "    graph[edge[0]][edge[1]][edge[2]]['actual_travel_time'] = float(e['actual_travel_time'])\n",
    "# Actual travel time should be saved in the graph now\n",
    "#real_calculation = 0\n",
    "#for edge in tqdm(graph.edges):\n",
    "#    # length is meters, speed_kph is kph (duh), maxspeed has units in string, and travel_time is seconds\n",
    "#    e = graph[edge[0]][edge[1]][edge[2]]\n",
    "#    if isinstance(e['osmid'], list):\n",
    "#        # Some graph edges are made up of multiple OSM ways apparently\n",
    "#        for osmid in e['osmid']:\n",
    "#            try:\n",
    "#                meters_per_second = speed_raw.at[osmid, 'speed_mph_mean']*0.44704    # Convert to meters/sec\n",
    "#                time = e['length']/meters_per_second\n",
    "#                real_calculation += 1\n",
    "#                break\n",
    "#            except (KeyError, ZeroDivisionError):\n",
    "#                time = e['travel_time']     # Backup (i.e. length/speed limit) if Uber data isn't available\n",
    "#    else:\n",
    "#        try:\n",
    "#            meters_per_second = speed_raw.at[e['osmid'], 'speed_mph_mean']*0.44704\n",
    "#            time = e['length']/meters_per_second\n",
    "#            real_calculation += 1\n",
    "#        except (KeyError, ZeroDivisionError):\n",
    "#            time = e['travel_time']\n",
    "#    if isinstance(time, pd.Series):\n",
    "#        # TODO Bug check why this is happening, but not late at night\n",
    "#        time = time.mean()\n",
    "#    graph[edge[0]][edge[1]][edge[2]]['actual_travel_time'] = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nuclear-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bounding box is around 60x30 miles, so 250 per side gives ~1 point per quarter mile on the longer side\n",
    "lats = np.linspace(bbox[1], bbox[0], num=250, dtype=np.float32)\n",
    "lons = np.linspace(bbox[3], bbox[2], num=lats.shape[0], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "quarterly-child",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number farther than one kilometer: 54601 Number overall: 62500\n"
     ]
    }
   ],
   "source": [
    "#all_nearest_nodes, dists = ox.distance.nearest_nodes(graph, np.repeat(lons, lats.shape[0]), np.tile(lats, lats.shape[0]), return_dist=True)\n",
    "#print('Number farther than one kilometer:', np.count_nonzero(np.asarray(dists) < 1000), 'Number overall:', len(all_nearest_nodes))\n",
    "# If it's more than a kilometer from an actual point then we're probably in the water/somewhere no one lives\n",
    "#all_nearest_nodes = np.asarray(all_nearest_nodes)[np.asarray(dists) < 1000]\n",
    "#np.save(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\nodes.npy', all_nearest_nodes)\n",
    "all_nearest_nodes = np.load(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\nodes.npy')\n",
    "food_closest_nodes = np.full(all_nearest_nodes.shape[0], -1, dtype=np.int64)\n",
    "food_closest_travel_times = np.full(all_nearest_nodes.shape[0], np.nan, dtype=np.float32)\n",
    "physical_closest_nodes = food_closest_nodes.copy()\n",
    "physical_closest_travel_times = food_closest_travel_times.copy()\n",
    "transport_closest_nodes = food_closest_nodes.copy()\n",
    "transport_closest_travel_times = food_closest_travel_times.copy()\n",
    "education_closest_nodes = food_closest_nodes.copy()\n",
    "education_closest_travel_times = food_closest_travel_times.copy()\n",
    "worship_closest_nodes = food_closest_nodes.copy()\n",
    "worship_closest_travel_times = food_closest_travel_times.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "continuing-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "#food_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in food_places], [x.y for x in food_places], return_dist=True)\n",
    "#print('Found food', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 1000), 'Number total:', len(food_nodes))\n",
    "#food_nodes = np.asarray(food_nodes)[np.asarray(dists) < 1000]\n",
    "#physical_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in physical_places], [x.y for x in physical_places], return_dist=True)\n",
    "#print('Found physical', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 1000), 'Number total:', len(physical_nodes))\n",
    "#physical_nodes = np.asarray(physical_nodes)[np.asarray(dists) < 1000]\n",
    "#transport_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in transport_places], [x.y for x in transport_places], return_dist=True)\n",
    "#print('Found transport', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 1000), 'Number total:', len(transport_nodes))\n",
    "#transport_nodes = np.asarray(transport_nodes)[np.asarray(dists) < 1000]\n",
    "#education_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in education_places], [x.y for x in education_places], return_dist=True)\n",
    "#print('Found education', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 1000), 'Number total:', len(education_nodes))\n",
    "#education_nodes = np.asarray(education_nodes)[np.asarray(dists) < 1000]\n",
    "#worship_nodes, dists = ox.distance.nearest_nodes(graph, [x.x for x in worship_places], [x.y for x in worship_places], return_dist=True)\n",
    "#print('Found worship', 'Number within 1km:', np.count_nonzero(np.asarray(dists) < 1000), 'Number total:', len(worship_nodes))\n",
    "#worship_nodes = np.asarray(worship_nodes)[np.asarray(dists) < 1000]\n",
    "#np.save(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\food_nodes.npy', food_nodes)\n",
    "#np.save(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\physical_nodes.npy', physical_nodes)\n",
    "#np.save(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\transport_nodes.npy', transport_nodes)\n",
    "#np.save(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\education_nodes.npy', education_nodes)\n",
    "#np.save(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\worship_nodes.npy', worship_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "provincial-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_nodes = np.load(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\food_nodes.npy')\n",
    "physical_nodes = np.load(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\physical_nodes.npy')\n",
    "transport_nodes = np.load(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\transport_nodes.npy')\n",
    "education_nodes = np.load(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\education_nodes.npy')\n",
    "worship_nodes = np.load(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\food_nodes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abandoned-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_lat_lons = np.array([[graph.nodes[x]['x'] for x in food_nodes], [graph.nodes[x]['y'] for x in food_nodes]], dtype=np.float32).T\n",
    "physical_lat_lons = np.array([[graph.nodes[x]['x'] for x in physical_nodes], [graph.nodes[x]['y'] for x in physical_nodes]], dtype=np.float32).T\n",
    "transport_lat_lons = np.array([[graph.nodes[x]['x'] for x in transport_nodes], [graph.nodes[x]['y'] for x in transport_nodes]], dtype=np.float32).T\n",
    "education_lat_lons = np.array([[graph.nodes[x]['x'] for x in education_nodes], [graph.nodes[x]['y'] for x in education_nodes]], dtype=np.float32).T\n",
    "worship_lat_lons = np.array([[graph.nodes[x]['x'] for x in worship_nodes], [graph.nodes[x]['y'] for x in worship_nodes]], dtype=np.float32).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "attempted-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_tree = KDTree(food_lat_lons)\n",
    "physical_tree = KDTree(physical_lat_lons)\n",
    "transport_tree = KDTree(transport_lat_lons)\n",
    "education_tree = KDTree(education_lat_lons)\n",
    "worship_tree = KDTree(worship_lat_lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "capital-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 54601/54601 [00:13<00:00, 4179.34it/s]\n"
     ]
    }
   ],
   "source": [
    "closest_food_nodes = []\n",
    "closest_physical_nodes = []\n",
    "closest_transport_nodes = []\n",
    "closest_education_nodes = []\n",
    "closest_worship_nodes = []\n",
    "for sample_node in tqdm(all_nearest_nodes):\n",
    "    idxes = food_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_food_nodes.append(food_nodes[idxes])\n",
    "    idxes = physical_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_physical_nodes.append(physical_nodes[idxes])\n",
    "    idxes = transport_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_transport_nodes.append(transport_nodes[idxes])\n",
    "    idxes = education_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_education_nodes.append(education_nodes[idxes])\n",
    "    idxes = worship_tree.query((graph.nodes[sample_node]['x'], graph.nodes[sample_node]['y']), k=5)[1]\n",
    "    closest_worship_nodes.append(worship_nodes[idxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "weighted-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache    # Trying to speed things up a little\n",
    "def shortest_path(source, target):\n",
    "    return nx.shortest_path_length(graph, source=source, target=target, weight='actual_travel_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "black-decline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 54601/54601 [4:14:06<00:00,  3.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, sample_node in enumerate(tqdm(all_nearest_nodes)):\n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for food_node in closest_food_nodes[i]:\n",
    "        #food_node = ox.distance.nearest_nodes(graph, food_places.iat[k].x, food_places.iat[k].y)\n",
    "        shortest = shortest_path(sample_node, food_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = food_node\n",
    "    food_closest_nodes[i] = shortest_node\n",
    "    food_closest_travel_times[i] = current_shortest\n",
    "    \n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for physical_node in closest_physical_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, physical_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = physical_node\n",
    "    physical_closest_nodes[i] = shortest_node\n",
    "    physical_closest_travel_times[i] = current_shortest\n",
    "    \n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for transport_node in closest_transport_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, transport_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = transport_node\n",
    "    transport_closest_nodes[i] = shortest_node\n",
    "    transport_closest_travel_times[i] = current_shortest\n",
    "    \n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for education_node in closest_education_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, education_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = education_node\n",
    "    education_closest_nodes[i] = shortest_node\n",
    "    education_closest_travel_times[i] = current_shortest\n",
    "    \n",
    "    current_shortest = np.inf\n",
    "    shortest_node = 0\n",
    "    for worship_node in closest_worship_nodes[i]:\n",
    "        shortest = shortest_path(sample_node, worship_node)\n",
    "        if shortest < current_shortest:\n",
    "            current_shortest = shortest\n",
    "            shortest_node = worship_node\n",
    "    worship_closest_nodes[i] = shortest_node\n",
    "    worship_closest_travel_times[i] = current_shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "structured-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(r'C:\\Users\\willd\\Documents\\Georgia Tech\\CSE6424\\Project\\nearest.hdf5', 'w') as h5:\n",
    "    h5.create_dataset('nodes', data=all_nearest_nodes)\n",
    "    h5.create_dataset('nodes_x', data=np.array([graph.nodes[x]['x'] for x in all_nearest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('nodes_y', data=np.array([graph.nodes[x]['y'] for x in all_nearest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_food_nodes', data=food_closest_nodes)\n",
    "    h5.create_dataset('closest_food_nodes_travel_time', data=food_closest_travel_times)\n",
    "    h5.create_dataset('closest_food_nodes_x', data=np.array([graph.nodes[x]['x'] for x in food_closest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_food_nodes_y', data=np.array([graph.nodes[x]['y'] for x in food_closest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_physical_nodes', data=physical_closest_nodes)\n",
    "    h5.create_dataset('closest_physical_nodes_travel_time', data=physical_closest_travel_times)\n",
    "    h5.create_dataset('closest_physical_nodes_x', data=np.array([graph.nodes[x]['x'] for x in physical_closest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_physical_nodes_y', data=np.array([graph.nodes[x]['y'] for x in physical_closest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_transport_nodes', data=transport_closest_nodes)\n",
    "    h5.create_dataset('closest_transport_nodes_travel_time', data=transport_closest_travel_times)\n",
    "    h5.create_dataset('closest_transport_nodes_x', data=np.array([graph.nodes[x]['x'] for x in transport_closest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_transport_nodes_y', data=np.array([graph.nodes[x]['y'] for x in transport_closest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_education_nodes', data=education_closest_nodes)\n",
    "    h5.create_dataset('closest_education_nodes_travel_time', data=education_closest_travel_times)\n",
    "    h5.create_dataset('closest_education_nodes_x', data=np.array([graph.nodes[x]['x'] for x in education_closest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_education_nodes_y', data=np.array([graph.nodes[x]['y'] for x in education_closest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_worship_nodes', data=worship_closest_nodes)\n",
    "    h5.create_dataset('closest_worship_nodes_travel_time', data=worship_closest_travel_times)\n",
    "    h5.create_dataset('closest_worship_nodes_x', data=np.array([graph.nodes[x]['x'] for x in worship_closest_nodes], dtype=np.float32))\n",
    "    h5.create_dataset('closest_worship_nodes_y', data=np.array([graph.nodes[x]['y'] for x in worship_closest_nodes], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-dimension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ox]",
   "language": "python",
   "name": "conda-env-ox-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
